{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rD3ooOrX_2JQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from torchvision import datasets\n",
    "#import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from models.modelsList import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDn2NnMf_Lum",
    "outputId": "59e1e30e-4ce3-4abc-9b73-e1d9740d3037"
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fv6m4zd_2JU"
   },
   "source": [
    "# data upload & checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8Qr1IuOD4Vc",
    "outputId": "31951975-4a10-427e-90d7-99fc4b46042c"
   },
   "outputs": [],
   "source": [
    "\n",
    "from qutip import fidelity, Qobj\n",
    "from models.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q9fWFxR_2JW"
   },
   "source": [
    "1. data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycr4tDdD_2JW"
   },
   "outputs": [],
   "source": [
    "foldertype= 'A/depotsts/'\n",
    "url ='data/fromMeasurementSettings/'+foldertype\n",
    "#url = 'data/'data=pd.read_csv(url+'train_org.csv')\n",
    "data=pd.read_csv(url+'train_org.csv')\n",
    "data_noise=pd.read_csv(url+'train_noise.csv')\n",
    "testorg = pd.read_csv(url+'depo02test_org.csv')\n",
    "testnoise = pd.read_csv(url+'depo02test_noise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Td8F0fD_2JW"
   },
   "source": [
    "2. splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ehGLjyA_2JX"
   },
   "outputs": [],
   "source": [
    "# first off, I split the training datasets into train and validation\n",
    "split = 30000\n",
    "trainA, valA = data[1:split], data[split:39999] #I start form row 1 to be sure to avoid the panda header\n",
    "trainNoise, valNoise = data_noise[1:split],data_noise[split:-1]\n",
    "print(trainA.shape),print(valA.shape),print(trainNoise.shape),print(valNoise.shape)\n",
    "del(data)\n",
    "del(data_noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZw9U7_g_2JX"
   },
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zq2gsby-_2JX",
    "outputId": "e6f33c03-da29-47e8-a70c-43db14afc1d2"
   },
   "outputs": [],
   "source": [
    "trainset=attentionDataset(trainA, trainNoise)\n",
    "valset = attentionDataset(valA, valNoise)\n",
    "\n",
    "testset=attentionDataset(testorg[:10], testnoise[:10])\n",
    "\n",
    "del(testorg)\n",
    "del(testnoise)\n",
    "\n",
    "\n",
    "torch.manual_seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTENTION BASED MODEL initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size= 200\n",
    "epochs=30\n",
    "#VECCIO VALORE DI EPOCHS 30\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Netbeta(256,3,1,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNdDm6YI_2JZ",
    "outputId": "b9a32fda-da92-445d-b3f7-e7d10cdb40c4"
   },
   "outputs": [],
   "source": [
    "\n",
    "#model=AutoEncoder(myenc,mydec).to(device)\n",
    "model = model.to(device)\n",
    "#print(model)\n",
    "#summary(model, input_size=(1,16,16))\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr= lr)\n",
    "#just a MSE\n",
    "theloss = donatoLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wVWMvw8_2JZ"
   },
   "source": [
    "### dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lnGpDVL_2JZ"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWyvNrLh_2Ja"
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## starting the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7Gn3-6l_2Ja",
    "outputId": "7e779e34-3423-4b89-dbcb-bb57c5f06529"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(epochs)):\n",
    "    train_loss=0.\n",
    "\n",
    "\n",
    "    for batchd in train_dataloader:\n",
    "        model.train()\n",
    "        noisy_img, org_img=batchd\n",
    "       \n",
    "        #shift batch dimension to the beginning according to documentation for Conv layer\n",
    "\n",
    "        #print(type(noisy_img))\n",
    "\n",
    "        noisy_img = noisy_img.to(device)\n",
    "        org_img = org_img.to(device)\n",
    "       \n",
    "        noisy_img = torch.reshape(noisy_img,(noisy_img.shape[0],1,256))\n",
    "        denoised_img=model(noisy_img)\n",
    "        #denoised_img=denoised_img.permute(0,3,1,2)\n",
    "        #loss=criterion(denoised_img, org_img) #tra quella aggiustata e quella originale senza noise\n",
    "        loss=theloss(denoised_img, org_img,0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    valid_loss = 0\n",
    "\n",
    "    for inputs in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            noisy_img, org_img= inputs\n",
    "\n",
    "\n",
    "            #print(type(noisy_img))\n",
    "\n",
    "            noisy_img = noisy_img.to(device)\n",
    "            org_img = org_img.to(device)\n",
    "\n",
    "            noisy_img = torch.reshape(noisy_img,(noisy_img.shape[0],1,256))\n",
    "            denoised_img=model(noisy_img)\n",
    "            #denoised_img=denoised_img.permute(0,3,1,2)\n",
    "            #loss=criterion(denoised_img, org_img) #tra quella aggiustata e quella originale senza noise\n",
    "            vloss=theloss(denoised_img, org_img,0)\n",
    "\n",
    "            valid_loss+=vloss.item()\n",
    "\n",
    "\n",
    "    #print(epochs, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader))\n",
    "    print(\"Epochs {} TRAIN_loss {} and VALID_loss {}\".format(i+1,train_loss/len(train_dataloader),valid_loss/len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ELhwVg__2Ja"
   },
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model uploads (when needed). \n",
    "Here you can just run inference of the trained model, or upload a trained one and directly using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(model)\n",
    "\n",
    "# map_location=torch.device('cpu')\n",
    "#model = torch.load('models/measurementSettingsModels/Dep0)TransformerDUEMeasurementSettingsA-MSE.pth',map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JazfjK5u_2Jb",
    "outputId": "2085d7a1-fce2-4c4e-ae8a-80cfe3cd969b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reconstructions = []\n",
    "originals = []\n",
    "modelInputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for inputs in test_dataloader:\n",
    "    model.eval()\n",
    "\n",
    "    noisy_img, org_img= inputs\n",
    "\n",
    "    noisy_img = noisy_img.to(device)\n",
    "    org_img = org_img.to(device)\n",
    "    noisy_img = torch.reshape(noisy_img,(noisy_img.shape[0],1,256))\n",
    "    denoised_img=model(noisy_img)\n",
    "    #print(noisy_img.shape)\n",
    "    #step two\n",
    "\n",
    "    for _ in range(3):\n",
    "        denoised_img = model(torch.reshape(denoised_img,(10,1,256)))\n",
    "      \n",
    "    reconstructions.extend(denoised_img.cpu().detach())\n",
    "    originals.extend(org_img.cpu().detach())\n",
    "    modelInputs.extend(noisy_img.cpu().detach())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## density matricy trace value test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reconstructions)\n",
    "unit = []\n",
    "for el in reconstructions:\n",
    "    unit.append(el[0])\n",
    "np.mean(unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SWKsKwW_2Jc"
   },
   "source": [
    "## state reconstruction (projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK-9THbw_2Jc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ulteriore postprocessing, ritorno a correlatori nella forma originale e proietto\n",
    "\n",
    "#first off, generate the basis once!\n",
    "pauliBasis = generatePaulimatrices()\n",
    "\n",
    "fidNoisyTarget = []\n",
    "fidProjectedTarget =[]\n",
    "PurNoisyTarget = []\n",
    "PurProjectedTarget =[]\n",
    "\n",
    "def unnormalizeForAttention(inp):\n",
    "    inp=inp.numpy()\n",
    "    inp = 2*inp -1\n",
    "    inp= delete(inp,0)\n",
    "    return inp\n",
    "i = 0\n",
    "di = 100\n",
    "\n",
    "def globalDepo(rm):\n",
    "\tp= 0.2\n",
    "\ti = np.eye(16,16)\n",
    "\tdep = (1-p)*rm + (p/16.)*i\n",
    "\treturn dep\n",
    "#pbasis = generatePaulimatrices()\n",
    "\n",
    "for corretta, rumorosa, originale in zip(reconstructions[i:i+di], modelInputs[i:i+di], originals[i:i+di]):\n",
    "\n",
    "    corretta_vec = unnormalizeForAttention(corretta)\n",
    "    rumorosa_vec = unnormalizeForAttention(rumorosa)\n",
    "    originale_vec = unnormalizeForAttention(originale)\n",
    "\n",
    "    #print('rumoros',rumorosa_vec[:20].shape)\n",
    "    #OLD RANDOM SET\n",
    "    #corrs_counts='100101000010110000000000001010000000001100000000000000000000000000000000000000000010000000000010000000000100000000100000000000000000000110010000000000110000000001000000000000000000010000001000010000000000000000000010100000010000000101000000000010000000010'\n",
    " \n",
    "\n",
    "    #several corrs_counts\n",
    "    f = open('data/fromMeasurementSettings/'+foldertype+'/corrsCountList.txt', 'r')\n",
    "    corrs_counts = f.read()\n",
    "    print(len(corrs_counts))\n",
    "    \n",
    "    #2) PROIEZIONE\n",
    "    tiponorma=\"fro\"\n",
    "\n",
    "    #print(corretta_vec)\n",
    "    #nota, inserisco rumorosa_vec invece di originale vec\n",
    "    corrttproj_dm=proj(corrs_counts, corretta_vec, rumorosa_vec,tiponorma,pauliBasis)[1]\n",
    "    org_dm=stato_from_corr(originale_vec, pauliBasis)\n",
    "    org_dm = globalDepo(org_dm)\n",
    "    \n",
    "    noisy_dm=stato_from_corr(rumorosa_vec, pauliBasis)\n",
    "\n",
    "\n",
    "    print('PROJ PURiTY', np.trace(corrttproj_dm@corrttproj_dm)) \n",
    "    \n",
    "    fidNoisyTarget.append(fidelity(Qobj(noisy_dm), Qobj(org_dm)))\n",
    "    fidProjectedTarget.append(fidelity(Qobj(corrttproj_dm), Qobj(org_dm)))\n",
    "\n",
    "    PurNoisyTarget.append((Qobj(noisy_dm)*Qobj(noisy_dm)).tr())\n",
    "    PurProjectedTarget.append((Qobj(corrttproj_dm)*Qobj(corrttproj_dm)).tr() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRACE NORM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceNormTest(m):\n",
    " \n",
    "    e = np.linalg.eigvals(m)\n",
    "    return sum(np.abs(e))\n",
    "tt = []\n",
    "\n",
    "for el in reconstructions:\n",
    "    cc = unnormalizeForAttention(el)\n",
    "    netOut = stato_from_corr(cc, pauliBasis)\n",
    "    tt.append(traceNormTest(netOut))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMuySiKz_2Jc"
   },
   "source": [
    "## Plots, averaged values, savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fidNoisyTarget), np.mean(fidProjectedTarget), np.mean(PurNoisyTarget), np.mean(PurProjectedTarget), len(fidNoisyTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotfold = 'fromMeasurementSets/'+'B4/'\n",
    "torch.save(reconstructions,'parallel/'+str(plotfold)+'/SetB4Transformer-reconstruction6k')\n",
    "torch.save(originals,'parallel/'+str(plotfold)+'/SetB4Transformer-originals6k')\n",
    "torch.save(modelInputs,'parallel/'+str(plotfold)+'/SetB4Transformer-modelInputs6k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'models/measurementSettingsModels/Dep0TransformerDUEMeasurementSettings'+foldertype[0]+'-MSE.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del(model)\n",
    "del(fidNoisyTarget)\n",
    "del(fidProjectedTarget)\n",
    "del(PurNoisyTarget)\n",
    "del(PurProjectedTarget)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomcorrs_TEST='100101000010110000000000001010000000001100000000000000000000000000000000000000000010\\\n",
    "#    00000000001000000000010000000010000000000000000000011001000000000011000000000100000000000000000001000\\\n",
    "#    0001000010000000000000000000010100000010000000101000000000010000000010'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
