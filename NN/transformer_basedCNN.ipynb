{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vF4HqtQR-QiT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import distributions\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGyreKT2nsul",
        "outputId": "69875c17-5164-4c65-b299-10aa33ca157f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qkIftzd1oXgw"
      },
      "outputs": [],
      "source": [
        "trials = 1000000\n",
        "\n",
        "url = '../PRAlikeData/qutrit'+str(trials)+'RandomSic.npy'\n",
        "#url2 = '/content/drive/MyDrive/data4Ent/PRA/gltest_'+str(trials)+'.npy'\n",
        "#url3 = '/content/drive/MyDrive/data4Ent/PRA/qutritIdealBorns_tetra.npy'\n",
        "#url = '/content/drive/MyDrive/data4Ent/MtoMdata/2qutritGlobDepo0.2betaTrial1^6KBorns_tetra.npy'\n",
        "\n",
        "tomo = np.load(url, allow_pickle=True)\n",
        "#gl = np.load(url2, allow_pickle= True)\n",
        "#gl = np.reshape(gl, (1000,-1))\n",
        "\n",
        "#ideals = np.load(url3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nXlspthJuKEi"
      },
      "outputs": [],
      "source": [
        "tomo_train, tomo_temp = train_test_split(tomo, test_size=0.7, random_state=1)\n",
        "tomo_valid,tomo_test = train_test_split(tomo_temp, test_size=0.93 ,random_state=1)\n",
        "\n",
        "tomo_test, etc = train_test_split( tomo_test, test_size = 0.92 )\n",
        "\n",
        "import random\n",
        "valid = tomo_valid\n",
        "train = tomo_train\n",
        "test = tomo_test\n",
        "\n",
        "random.shuffle(train)\n",
        "random.shuffle(valid)\n",
        "random.shuffle(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkBj4NnLQjUC",
        "outputId": "7f8327f7-352c-4871-92a1-f711c53e5ae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6000, 18), (980, 18), (1041, 18))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train.shape, valid.shape, test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U9qFDDmWPgvO"
      },
      "outputs": [],
      "source": [
        "class StatesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x):\n",
        "        super().__init__()\n",
        "        self.x = x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WXOabFuZ7i3X"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7deFj1YM4Ea8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_dataset = StatesDataset(train)\n",
        "evaluation_dataset = StatesDataset(valid)\n",
        "test_dataset = StatesDataset(test)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5EGTchy_PAD_"
      },
      "source": [
        "Fix the seeds for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xQlaDA28cK3",
        "outputId": "f675ed12-aed4-4100-ec6d-23b6feb4f3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x2043a7ed6d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "torch.manual_seed(13)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VB_7zGhK7kl5"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "_3t-8DE-ViaY",
        "outputId": "5dc57868-3e15-400a-826f-5010500613da"
      },
      "outputs": [],
      "source": [
        "del(themodelbeta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrOLNJq4WxzF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Netbeta(nn.Module):\n",
        "    def __init__(self, state_local_d, num_low_triang, out_channel, nheads, dim_ff ):\n",
        "        super().__init__()\n",
        "      \n",
        "        #ENCODING\n",
        "        self.conv1 = nn.Conv1d(1, out_channel,2 ) #new input feature will be state_local_d**2 -1\n",
        "\n",
        "        #DECODING\n",
        "        self.enc_transf = nn.TransformerEncoderLayer(d_model = 8, nhead = nheads, dim_feedforward = dim_ff, batch_first = True) # hereh hidden_size must be D-out/9 to become d_out after flattening\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.enc_stack = nn.TransformerEncoder(self.enc_transf, num_layers=1)\n",
        "        self.T = torch.nn.Tanh()\n",
        "      \n",
        "        #diagonal part\n",
        "        self.cholesky_diag = torch.nn.Linear(out_channel*8, state_local_d)\n",
        "\n",
        "        # (n*n +n)/2 strictly lower diagonal elements\n",
        "        self.cholesky_lower_t = torch.nn.Linear(out_channel*8, 2*num_low_triang)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #ENCODING\n",
        "\n",
        "        x = F.selu(self.conv1(x)) # out1 = (c1(inp))\n",
        "\n",
        "        #DECODING\n",
        "\n",
        "        x= self.g(self.enc_stack(x) )\n",
        "        x = torch.flatten(x,1)\n",
        "\n",
        "        diags = self.relu(self.cholesky_diag(x)) \n",
        "        off_diags = self.T(self.cholesky_lower_t(x))\n",
        "\n",
        "        return diags, off_diags\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zamKBCtwLDZU"
      },
      "source": [
        "# Training for beta version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M-M66zE-Pr5I"
      },
      "outputs": [],
      "source": [
        "local_dim = 3\n",
        "dim = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "5nU-flGMLpYE",
        "outputId": "229589c8-77f6-41a4-e537-6aadb0245276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0\n"
          ]
        }
      ],
      "source": [
        "num_killed_inputs = 0\n",
        "\n",
        "input_dim = local_dim**(2*dim) - num_killed_inputs\n",
        "batch_size = 1000\n",
        "\n",
        "statedim = local_dim**dim\n",
        "lowerval = (statedim**2 -statedim)/2\n",
        "print(lowerval)\n",
        "\n",
        "device = \"cpu\"\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "netb = Netbeta(int(local_dim) , int(lowerval), 2,1,10) #it was 12 channels and 10 ff dim in all other tests\n",
        "themodelbeta  = netb.to(device)\n",
        "themodelbeta = themodelbeta.double()\n",
        "\n",
        "\n",
        "def normalization_loss(input1,input2):\n",
        "\n",
        "  single_vector = torch.cat((input1,input2),dim=1)\n",
        "  batchsize = input1.shape[0]\n",
        "  \n",
        "  #return torch.abs(torch.sum(torch.norm(single_vector, p ='fro', dim=1))/batchsize -1 )\n",
        "  return torch.mean(torch.norm(single_vector, p ='fro', dim=1))/batchsize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FHE6JS2OSPa1"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    pin_memory=True)\n",
        "\n",
        "valid_dataloader = torch.utils.data.DataLoader(\n",
        "    evaluation_dataset, batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    pin_memory=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    pin_memory=True)\n",
        "\n",
        "#gl_dataloader = torch.utils.data.DataLoader(\n",
        "#    gl_dataset, batch_size = batch_size, shuffle =False,\n",
        "#    pin_memory = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "m6OVG3DkLIlv",
        "outputId": "a7d5a051-5fcc-4e84-ee25-aefb3a54e7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "0 0.44120999508130904 0.3886148075177755\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "1 0.3977174013511362 0.35410635296940385\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "2 0.3702564182677612 0.3286280296409703\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "3 0.3520541849615532 0.3086883890575385\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "4 0.33580841523541793 0.29179644872043986\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "5 0.32163618908774705 0.27739106821079623\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "6 0.31157810394809826 0.26443310184744767\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "7 0.297595761822258 0.25289047490944283\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "8 0.2883863701513782 0.24292751288080114\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "torch.Size([1000, 3]) torch.Size([1000, 6]) torch.Size([1000, 3]) torch.Size([1000, 6])\n",
            "9 0.2807398106492152 0.2336918212600789\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rec_loss = torch.nn.MSELoss()\n",
        "optimizer = optim.RMSprop(themodelbeta.parameters(), lr=learning_rate)\n",
        "\n",
        "val_hist = []\n",
        "train_hist = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    for inputs in train_dataloader:\n",
        "       \n",
        "        themodelbeta.train()\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "       \n",
        "        low_t = inputs[:, local_dim**(2*dim) + local_dim**dim - num_killed_inputs :]\n",
        "        diagel = inputs[:,local_dim**(2*dim): local_dim**(2*dim) + local_dim**(dim) - num_killed_inputs]\n",
        "\n",
        "        #INPUTS RESHAPING\n",
        "\n",
        "        newin = torch.reshape(inputs[:,:local_dim**(2*dim) - num_killed_inputs ], (inputs.shape[0],1,local_dim**(2*dim )) )\n",
        "        out1, out2 = themodelbeta(newin)\n",
        "        \n",
        "        print(out1.shape, out2.shape, diagel.shape,low_t.shape)\n",
        "        \n",
        "        #out1 = themodelbeta(newin)\n",
        "        loss = rec_loss(out1, diagel) + rec_loss(out2, low_t) + normalization_loss(out1,out2)\n",
        "        #loss = rec_loss(out1,inputs[:,9:]) \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    valid_loss = 0\n",
        "    for inputs in valid_dataloader:\n",
        "        with torch.no_grad():\n",
        "            themodelbeta.eval()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            low_t = inputs[:, local_dim**(2*dim) + local_dim**dim - num_killed_inputs :]\n",
        "            diagel = inputs[:,local_dim**(2*dim): local_dim**(2*dim) + local_dim**(dim) - num_killed_inputs]\n",
        "\n",
        "           \n",
        "            newinval = torch.reshape(inputs[:,:local_dim**(2*dim) - num_killed_inputs ], (inputs.shape[0],1,local_dim**(2*dim)) )\n",
        "            out1, out2 = themodelbeta(newinval)\n",
        "\n",
        "            loss = rec_loss(out1, diagel) + rec_loss(out2, low_t) + normalization_loss(out1,out2)\n",
        "            #loss = rec_loss(out2,inputs[:,9:]) \n",
        "\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    \n",
        "    print(epoch, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader))\n",
        "    val_hist.append(valid_loss/len(valid_dataloader))\n",
        "    train_hist.append(train_loss/len(train_dataloader))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V1avbT5eOd62"
      },
      "source": [
        "# Test. Quantum fidelity state reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-ABqwoQUSOH"
      },
      "outputs": [],
      "source": [
        "def return_matrix_elements(stuff,d,local_dim): \n",
        "\n",
        "\tdiag_len = local_dim**d\n",
        "\t#print(diag_len)\n",
        "\n",
        "\tnon_diag_len = (local_dim**(2*d) -diag_len)/2\n",
        "\t#print(non_diag_len)\n",
        "\n",
        "\t#head-up: local dim**(2d) is also the length of the initial state. The total dimension of the input is 2Xlocal dim**(2d)\n",
        "\n",
        "\tdiagel = stuff[local_dim**(2*d)  - num_killed_inputs : local_dim**(2*d)  + diag_len  - num_killed_inputs]\n",
        "\toffd = stuff[ local_dim**(2*d)  + diag_len -num_killed_inputs:  ]\n",
        "\t#print(len(imag))\n",
        "\treturn diagel, offd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP6-uvcEdaSm"
      },
      "outputs": [],
      "source": [
        "def rebuild_last(diags,offd,ind):\n",
        "    '''''\n",
        "    input.\n",
        "    diags : diags elements\n",
        "    offds : offdiagonal elements\n",
        "    rhoshape : just the dm dimension, e.g. number of rows\n",
        "    localDim : the number of level of each particle\n",
        "    numParticles : the total number of particles for tensor product\n",
        "\n",
        "    output.\n",
        "    m : reconstructed cholesky decoposition matrix\n",
        "    '''''\n",
        "    d = len(diags)\n",
        "    eye = np.eye(d,d)\n",
        "    mat = np.zeros((d,d),dtype = complex)\n",
        "\n",
        "    offvalues = [ (a+1j*b) for (a,b) in zip(offd[:int(len(offd)/2 ) ], offd[int(len(offd)/2):])  ]\n",
        "    mat[ind[0], ind[1]] = offvalues\n",
        "\n",
        "    return mat + eye*diags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r37vl0hzdi4e",
        "outputId": "441d5b99-e92b-4dd4-e464-97a05826013b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 3)\n"
          ]
        }
      ],
      "source": [
        "#just generate ones the index for the recosntruction using a dull matrix\n",
        "\n",
        "import qutip as qt\n",
        "def fid(a,b):\n",
        "  fid = qt.fidelity(qt.Qobj(a), qt.Qobj(b))\n",
        "  return torch.tensor(fid)\n",
        "\n",
        "#parameters\n",
        "buresdistance =0\n",
        "qfid =0\n",
        "j=0\n",
        "hs = []\n",
        "fids =[]\n",
        "\n",
        "# generate support diagonal matrix for reconstruction\n",
        "e = np.eye(local_dim**(dim),local_dim**(dim)) \n",
        "print(e.shape)\n",
        "\n",
        "#indeces for the reconstruction function\n",
        "ind = np.tril_indices_from(e,k=-1)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg3t7Z7ThYFB"
      },
      "source": [
        "# new test phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtgvNr2GhdTm",
        "outputId": "e66781ce-ea07-41cc-ee3b-75ea766e111d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "averaged quantum fidelity  0.9990 \n",
            "0.0012061989\n",
            "hilbert schmidt distance average  0.0020\n",
            "hilbert schmidt distance std  0.0029\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs in test_dataloader:\n",
        "  \n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #out_d is the diagonal, out_tr the triangluar values, real and complex altogether\n",
        "    newin = torch.reshape(inputs[:,:local_dim**(2*dim) - num_killed_inputs ], (inputs.shape[0],1,local_dim**2) )\n",
        "\n",
        "    out_d, out_tr = themodelbeta(newin) \n",
        "\n",
        "    for i in range(out_d.shape[0]):\n",
        "\n",
        "      #reconstructing cholesky from dataset input array. NO MORE NEEDED\n",
        "      diagel, offd = return_matrix_elements( inputs[i].cpu().numpy(), dim, local_dim) \n",
        "\n",
        "      original_chol = rebuild_last(diagel, offd , ind)\n",
        "\n",
        "      #reconstructing cholesky from neural network outputs\n",
        "\n",
        "      nn_diag = out_d[i].cpu().numpy()      \n",
        "      nn_offd = out_tr[i,:int(out_tr.shape[1])].cpu().numpy()\n",
        "      \n",
        "      nn_chol = rebuild_last(nn_diag, nn_offd, ind)\n",
        "\n",
        "      cholo=nn_chol@ nn_chol.conj().T\n",
        "      #purity = np.trace(cholo@cholo)\n",
        "      norm = np.trace(cholo)\n",
        "      #norm = 1\n",
        "\n",
        "      #fidelity between reconstructed and originals\n",
        "\n",
        "      fids.append(fid(original_chol@ original_chol.conj().T,cholo/norm) )\n",
        "      hs.append(qt.hilbert_dist(qt.Qobj(cholo/norm), qt.Qobj(original_chol@ original_chol.conj().T)))\n",
        "\n",
        "print(f\"averaged quantum fidelity {np.mean(fids): .4f} \")#dont forget the j to divide by\n",
        "\n",
        "print(np.std(fids))\n",
        "print(f\"hilbert schmidt distance average {np.mean(hs): .4f}\")\n",
        "print(f\"hilbert schmidt distance std {np.std(hs): .4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS9PLZPoRZoD"
      },
      "outputs": [],
      "source": [
        "del(themodelbeta)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oPMWtSh6Z69u"
      },
      "source": [
        "GUILLEM FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhWi55eNttjX"
      },
      "outputs": [],
      "source": [
        "test_gl = gl\n",
        "\n",
        "gl_dataset = StatesDataset(test_gl)\n",
        "gl_dataloader = torch.utils.data.DataLoader(\n",
        "    gl_dataset, batch_size = batch_size, shuffle =False,\n",
        "    pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWqKQIqDZ3Og"
      },
      "outputs": [],
      "source": [
        "glFile = []\n",
        "\n",
        "name = 'qutritTestSet_6Ktrain_'+str(trials)+'_CNNtransformer.npy'\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs in gl_dataloader:\n",
        "  \n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    #out_d is the diagonal, out_tr the triangluar values, real and complex altogether\n",
        "    newin = torch.reshape(inputs[:,: ], (inputs.shape[0],1,local_dim**2) )\n",
        "\n",
        "    out_d, out_tr = themodelbeta(newin) \n",
        "\n",
        "    for i in range(out_d.shape[0]):\n",
        "\n",
        "      #reconstructing cholesky from neural network outputs\n",
        "\n",
        "      nn_diag = out_d[i].cpu().numpy()      \n",
        "      nn_offd = out_tr[i,:int(out_tr.shape[1])].cpu().numpy()\n",
        "      \n",
        "      nn_chol = rebuild_last(nn_diag, nn_offd, ind)\n",
        "\n",
        "      cholo=nn_chol@ nn_chol.conj().T\n",
        "      #purity = np.trace(cholo@cholo)\n",
        "      norm = np.trace(cholo)\n",
        "\n",
        "      glFile.append(cholo/norm)\n",
        "  \n",
        "  np.save(name, glFile)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0TIf8T1KixYa"
      },
      "source": [
        "SMALL TESTS AREA"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm2SZcZKOfg_"
      },
      "source": [
        "let's do embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B07Nf4kX_pP6"
      },
      "outputs": [],
      "source": [
        "latent_separable_representations = []\n",
        "\n",
        "for inputs in separable_test_dataloader:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        auto_encoder.eval()\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        encoded_x = auto_encoder.encoder(inputs)\n",
        "        latent_separable_representations.extend(encoded_x.cpu().detach().numpy())\n",
        "\n",
        "latent_entangled_representations = []\n",
        "\n",
        "for inputs in entangled_test_dataloader:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        auto_encoder.eval()\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        encoded_x = auto_encoder.encoder(inputs)\n",
        "        latent_entangled_representations.extend(encoded_x.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "075iIMsvO3Dq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx5XLnTfPEWa"
      },
      "outputs": [],
      "source": [
        "silhouette_score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwZizC-1PF6N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
